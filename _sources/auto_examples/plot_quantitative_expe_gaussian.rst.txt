
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_quantitative_expe_gaussian.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_quantitative_expe_gaussian.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_quantitative_expe_gaussian.py:


===========
Placeholder
===========

.. GENERATED FROM PYTHON SOURCE LINES 6-122



.. image:: /auto_examples/images/sphx_glr_plot_quantitative_expe_gaussian_001.png
    :alt: plot quantitative expe gaussian
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    0.01
    0 4.261440753936768
    100 0.9744200110435486
    200 0.49615657329559326
    300 0.32354632019996643
    400 0.23383426666259766
    500 0.17653827369213104
    600 0.13821224868297577
    700 0.11084777861833572
    800 0.09039384126663208
    900 0.0748412236571312
    0.1
    0 4.261440753936768
    100 0.060837045311927795
    200 0.01250891387462616
    300 0.005162161774933338
    400 0.003713753540068865
    500 0.0028241327963769436
    600 0.001979738473892212
    700 0.0013244962319731712
    800 0.0009058306459337473
    900 0.0006639374769292772
    10
    0 4.261440753936768
    100 0.8148616552352905
    200 0.9963881373405457
    300 1.0328468084335327
    400 1.1809982061386108
    500 1.6381587982177734
    600 1.8684601783752441
    700 1.2508316040039062
    800 1.3379956483840942
    900 1.3958888053894043
    0.01
    0 5.934197902679443
    100 1.5047675371170044
    200 0.7767242193222046
    300 0.5047093033790588
    400 0.3611060082912445
    500 0.269836962223053
    600 0.20467887818813324
    700 0.15686647593975067
    800 0.12162348628044128
    900 0.09552180022001266
    0.1
    0 5.934197902679443
    100 0.07217849791049957
    200 0.022257596254348755
    300 0.005842924118041992
    400 0.0017212574603036046
    500 0.0009486930212005973
    600 0.0008872192120179534
    700 0.0009376876405440271
    800 0.0010209694737568498
    900 0.001114755985327065
    10
    0 5.934197902679443
    100 1.3526358604431152
    200 1.3439550399780273
    300 1.568518042564392
    400 3.1890006065368652
    500 1.96482515335083
    600 1.3777024745941162
    700 1.0202194452285767
    800 1.6960029602050781
    900 1.0962271690368652






|

.. code-block:: default

    import torch
    from torch.optim import SGD
    from ksddescent import ksdd_lbfgs
    from ksddescent.contenders import svgd_pytorch
    from ksddescent.kernels import gaussian_stein_kernel_single
    import matplotlib.pyplot as plt
    import numpy as np
    from time import time
    from scipy.stats import entropy

    def average_curves(times, values):
        times = np.array(times)
        t_max = np.max(times)
        time_grid = np.linspace(0, t_max, 200)
        interp_values = [np.interp(time_grid, np.linspace(0, time, len(value)), value) for time, value in zip(times, values)]
        return time_grid, np.median(interp_values, axis=0)

    def score(x):
        return -x


    def sampler(n_points):
        return torch.randn(n_points, 1)


    def kl(x, true_samples, bins=None):
        n_samples = x.shape
        if bins is None:
            bins = int(np.sqrt(n_samples))
        hist_x, bins = np.histogram(x, bins=bins, density=False)
        hist_samples, _ = np.histogram(true_samples, bins=bins, density=False)
        return entropy(hist_x, hist_samples)


    def ksd(x, bw):
        K = gaussian_stein_kernel_single(x, score(x), bw)
        return K.mean().item() / bw


    p = 1

    def one_expe(n_samples, bw, step_svgd, step_mmd):
        x = .1 * torch.randn(n_samples, p)+ torch.randn(p)
        lbda = None
        n_iters = 1000
        max_iter = 1000
        x_list = []
        x_final = x.clone()
        x_regs = []
        t0 = time()
        ksdd_lbfgs(x, score, bw=bw, kernel='gaussian', max_iter=max_iter)
        t_ksd = time() - t0
        _, traj_ksd, _ = ksdd_lbfgs(x, score, bw=bw, kernel='gaussian', store=True, max_iter=max_iter)
        t_svgds = []
        traj_svgds = []
        for step in step_svgd:
            print(step)
            t0 = time()
            svgd_pytorch(x, score, step, n_iter=n_iters, bw=bw, verbose=True)
            t_svgd = time() - t0
            t_svgds.append(t_svgd)
            _, traj_svgd, _ = svgd_pytorch(x, score, step, n_iter=n_iters, bw=bw, store=True)
            traj_svgds.append(traj_svgd)
        true_samples = sampler(10000)
        kl_ksd = [kl(x[:, 0], true_samples) for x in traj_ksd]
        kl_svgd = np.array([[kl(x[:, 0], true_samples) for x in traj_svgd] for traj_svgd in traj_svgds])
        ksd_ksd = [ksd(x, bw) for x in traj_ksd]
        ksd_svgd = np.array([[ksd(x, bw) for x in traj_svgd] for traj_svgd in traj_svgds])
        return kl_ksd, kl_svgd, t_ksd, t_svgds, ksd_ksd, ksd_svgd

    bw = .1
    n_samples = 30
    n_expes = 2
    time_list = []
    steps_svgd = [.01, .1, 10]
    step_mmd = .01
    outputs = [one_expe(n_samples, bw, steps_svgd, step_mmd) for _ in range(n_expes)]


    kl_dict = {}
    kl_dict['ksd'] = [op[0] for op in outputs]
    kl_dict['svgd'] = {}
    for i, step in enumerate(steps_svgd):
        kl_dict['svgd'][step] = [op[1][i] for op in outputs]

    ksd_dict = {}
    ksd_dict['ksd'] = [op[4] for op in outputs]
    ksd_dict['svgd'] = {}
    for i, step in enumerate(steps_svgd):
        ksd_dict['svgd'][step] = [op[5][i] for op in outputs]
    times_ksds = np.array([op[2] for op in outputs])
    times_svgds_list = np.array([op[3] for op in outputs]).T

    timing = True



    f, axes = plt.subplots(1, 2, figsize=(5, 1))

    for to_plot_dict, title, axe in [(kl_dict, 'KL', axes[0]), (ksd_dict, r'KSD', axes[1])]:
        t_avg_ksd, plot_ksd = average_curves(times_ksds, to_plot_dict['ksd'])
        lw = 2
        axe.plot(t_avg_ksd, plot_ksd, color='blue', label='KSD', linewidth=lw)

        for step, times_svgds, label, color in zip(steps_svgd, times_svgds_list,
                                                ['SVGD, small step', 'SVGD, good step', 'SVGD, big step'],
                                                ['green', 'orange', 'red']):
            t_avg_svgd, plot_svgd = average_curves(times_svgds, to_plot_dict['svgd'][step])
            axe.plot(t_avg_svgd, plot_svgd, color=color, label=label, linewidth=lw)
        axe.set_yscale('log')
        x_ = axe.set_xlabel('Time (s.)')
        y_ = axe.set_ylabel(title)
        axe.grid()
    plt.subplots_adjust(wspace=.4)
    l_ = plt.legend(ncol=4, loc=(-1.75, 1.1), columnspacing=.7, handlelength=1, handletextpad=.3)
    plt.show()


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  7.704 seconds)


.. _sphx_glr_download_auto_examples_plot_quantitative_expe_gaussian.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_quantitative_expe_gaussian.py <plot_quantitative_expe_gaussian.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_quantitative_expe_gaussian.ipynb <plot_quantitative_expe_gaussian.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
