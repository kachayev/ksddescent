{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Effect of annealing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Pierre Ablin <pierre.ablin@ens.fr>\n#\n# License: MIT\n\nimport torch\nfrom ksddescent import ksdd_lbfgs\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ntorch.manual_seed(1)\n\n\ndef make_mog(centers, vars, weights):\n    weights = torch.tensor(weights)\n    weights /= weights.sum()\n\n    def score(x):\n        den = 0\n        top = 0\n        for center, var, weight in zip(centers, vars, weights):\n            exp = torch.exp(-0.5 * ((x - center) ** 2).sum(axis=1) / var)\n            den += weight * exp\n            top += weight * exp[:, None] * (x - center) / var\n        return -top / den[:, None]\n\n    def potential(x):\n        op = 0.0\n        for center, var, weight in zip(centers, vars, weights):\n            exp = torch.exp(-0.5 * ((x - center) ** 2).sum(axis=1) / var)\n            op += weight * exp\n        return torch.log(op)\n\n    def sampler(n_samples):\n        x = []\n        for c, v, w in zip(centers, vars, weights):\n            z = torch.randn(int(n_samples * w), 2)\n            z *= np.sqrt(v)\n            z += c\n            x.append(z.clone())\n        return torch.cat(x)\n\n    return score, potential, sampler\n\n\nvar = 0.1\nfac = 0.5\ncenters = [\n    torch.tensor([-1.0, -1.0]),\n    torch.tensor([1.0, 1]),\n    torch.tensor([1, -1]),\n]\nvariances = [var, var]\nweights = [0.5, 0.5]\n\nscore, potential, sampler = make_mog(centers, variances, weights)\n\nn_samples = 50\np = 2\n\nx = torch.randn(n_samples, p) / 3\n\nbeta = 0.1\n\n\ndef score_beta(x):\n    return beta * score(x)\n\n\nbw = 0.1\nnoise_level = 0.1\nstep = 0.01\nx_direct = ksdd_lbfgs(x, score, kernel=\"gaussian\", bw=bw).detach()\nx_final = ksdd_lbfgs(x, score_beta, kernel=\"gaussian\", bw=bw).detach()\nx_final2 = ksdd_lbfgs(x_final, score, kernel=\"gaussian\", bw=bw).detach()\n\nfor x, method, label in zip(\n    [x_direct, x_final, x_final2],\n    [\"direct\", \"hightemp\", \"lowtemp\"],\n    [r\"$\\beta=1$\", r\"$\\beta=0.1$\", r\"$\\beta=0.1 \\to 1$\"],\n):\n    plt.figure(figsize=(1.8, 1.8))\n    s = 5\n    plt.scatter(x[:, 0], x[:, 1], s=s, zorder=10)\n    plt.text(\n        -1.8,\n        1.5,\n        label,\n        color=\"k\",\n        bbox=dict(facecolor=\"white\", edgecolor=\"k\", alpha=1),\n    )\n\n    x_ = np.linspace(-2.0, 2.0)\n    y_ = np.linspace(-2.0, 2.0)\n    X, Y = np.meshgrid(x_, y_)\n    XX = torch.tensor(np.array([X.ravel(), Y.ravel()]).T)\n    Z = potential(XX).reshape(X.shape).detach().numpy()\n\n    plt.contour(X, Y, Z, levels=10, colors=\"k\", linestyle=\"dotted\")\n    plt.tick_params(\n        axis=\"both\",\n        which=\"both\",\n        bottom=False,\n        top=False,\n        labelbottom=False,\n        left=False,\n        right=False,\n        labelleft=False,\n    )\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}